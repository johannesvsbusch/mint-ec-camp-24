{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import image_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural Networks for Image Classification \n",
    "In the last exercises we learned about neural networks and how they can correctly classify complicated data. So far we have only looked at datasets with relatively few features. In the iris dataset we looked at data with 4 features (sepal_length, sepal_width, petal_length, petal_width). However, in machine learning we want to deal with much more complex data such as images. In this notebook we will use neural networks to **classify images of handwritten digits** (numbers from 0 to 9). These images come from the so-called MNIST dataset. The size of the images here is **28 x 28 pixels and it is in black and white**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load and Visualize the Dataset\n",
    "Let's first load the data and look at some examples of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and separate it into a train and a test set\n",
    "(x_train, y_train), (x_test, y_test) = image_classification.load_mnist()\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# plot some images from the test set\n",
    "image_classification.visualize_mnist(images = x_test, labels = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1:\n",
    "1. How many features do the images have?\n",
    "2. Can you think of some features that are more or less important than others?\n",
    "3. We now have 10 possible classes (before we had only two). Can you think of a way how we can use linear classifiers to distinguish between 10 classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Building the Classification Model\n",
    "First we will implement a simple neural network in Keras that we can use to classify the images. As an activation function, we here use the **Softmax function** that is often used for multi-class classification. It outputs a probability for every class with that the Network thinks, the image belongs to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our neural network\n",
    "network = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation = \"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# we here compile the model using categorical crossentropy as a loss function. The categorical crossentropy is low if the model predicts the correct class.\n",
    "network.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# we use this to save our results of training\n",
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start the training, let's check how well the network does without any training. The test accuracy is the percentage of images in the test set that our model predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this evaluates the network by predicting the labels of the test set and comparing the predictions and comparing these to the true labels\n",
    "score = network.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {100*score[1]:.4}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.2\n",
    "1. How many parameters does the network have? \n",
    "2. The test accuracy is not so great. What test accuracy would you have expected and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Training the Classification Model\n",
    "We now run the training loop for 10 epochs (in one epoch we use every image of the dataset once to train the network). Training can take a minute so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the name of the run as it will show up in the logs\n",
    "run_name = \"first_try\"\n",
    "# this trains the network\n",
    "out = network.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test),\n",
    "callbacks=[keras.callbacks.TensorBoard(f\"../logs/{run_name}\", update_freq=\"batch\")])\n",
    "# here we safe the train progress to compare it later\n",
    "accuracies[run_name] = {\"train\": out.history[\"accuracy\"], \"test\": out.history[\"val_accuracy\"]}\n",
    "# lets look at the test accuracy after training\n",
    "score = network.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {100*score[1]:.4}%\")\n",
    "# lets plot how our training went\n",
    "image_classification.plot_accuracies(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.3\n",
    "1. Which one of the graphs (train or test) is more important to assess the performance of our classifier?\n",
    "2. Do you think a linear classifier would have a better, worse or the same test accuracy? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Visualizing the results of Training\n",
    "Now let's look at some of the images and the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this predicts and visualizes the labels of the test set\n",
    "predictions = network.predict(x_test, verbose=0)\n",
    "image_classification.visualize_mnist(x_test, labels=y_test, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This already looks quite good. But there are still many images that are classified wrong. Let's look at some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we here look for images that are classified wrong and show some of them\n",
    "wrong_prediction_idxs = np.where(predictions.argmax(axis=-1) != y_test.argmax(axis=-1))\n",
    "image_classification.visualize_mnist(x_test[wrong_prediction_idxs[:6]],\n",
    "labels=y_test[wrong_prediction_idxs], predictions=predictions[wrong_prediction_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Try to get a better Accuracy!\n",
    "Now you can play around with the number of layers and neurons. Change the network structure and see what happens. You can also try to change the number of training epochs or batch size. Give your runs meaningful names so you can tell them apart in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # give your run a meaningful name!\n",
    "run_name = \"meaningful_name\"\n",
    "\n",
    "# this is our neural network -> play around with the number and size of layers, but don't forget to add activation functions.\n",
    "network = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation = \"relu\"),\n",
    "        keras.layers.Dense(10, activation = \"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# this compiles the network -> you can try to use the optimizer \"sgd\" instead\n",
    "network.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# this trains the network -> you can play around with the number of epochs or the batch size\n",
    "out = network.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test),\n",
    "callbacks=[keras.callbacks.TensorBoard(f\"../logs/{run_name}\")])\n",
    "\n",
    "# this saves the results\n",
    "accuracies[run_name] = {\"train\": out.history[\"accuracy\"], \"test\": out.history[\"val_accuracy\"]}\n",
    "\n",
    "# lets look at the test accuracy after training\n",
    "score = network.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {100*score[1]:.4}%\")\n",
    "\n",
    "# this plots the accuracies over epochs\n",
    "image_classification.plot_accuracies(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.5:\n",
    "1. What happens if you increase the number of epochs?\n",
    "2. How does the performance change if we add a hidden layer with many neurons (e.g., 1000)?\n",
    "3. What does the network do when we add a hidden layer with only one neuron?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mintec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
